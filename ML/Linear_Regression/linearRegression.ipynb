{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# load the dataset\n","data = pd.read_csv('admit_data2.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Serial No.</th>\n","      <th>GRE Score</th>\n","      <th>TOEFL Score</th>\n","      <th>University Rating</th>\n","      <th>SOP</th>\n","      <th>LOR</th>\n","      <th>CGPA</th>\n","      <th>Research</th>\n","      <th>Chance of Admit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>337</td>\n","      <td>118</td>\n","      <td>4</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>9.65</td>\n","      <td>1</td>\n","      <td>0.92</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>324</td>\n","      <td>107</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>4.5</td>\n","      <td>8.87</td>\n","      <td>1</td>\n","      <td>0.76</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>316</td>\n","      <td>104</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","      <td>8.00</td>\n","      <td>1</td>\n","      <td>0.72</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>322</td>\n","      <td>110</td>\n","      <td>3</td>\n","      <td>3.5</td>\n","      <td>2.5</td>\n","      <td>8.67</td>\n","      <td>1</td>\n","      <td>0.80</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>314</td>\n","      <td>103</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>8.21</td>\n","      <td>0</td>\n","      <td>0.65</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>395</th>\n","      <td>396</td>\n","      <td>324</td>\n","      <td>110</td>\n","      <td>3</td>\n","      <td>3.5</td>\n","      <td>3.5</td>\n","      <td>9.04</td>\n","      <td>1</td>\n","      <td>0.82</td>\n","    </tr>\n","    <tr>\n","      <th>396</th>\n","      <td>397</td>\n","      <td>325</td>\n","      <td>107</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","      <td>9.11</td>\n","      <td>1</td>\n","      <td>0.84</td>\n","    </tr>\n","    <tr>\n","      <th>397</th>\n","      <td>398</td>\n","      <td>330</td>\n","      <td>116</td>\n","      <td>4</td>\n","      <td>5.0</td>\n","      <td>4.5</td>\n","      <td>9.45</td>\n","      <td>1</td>\n","      <td>0.91</td>\n","    </tr>\n","    <tr>\n","      <th>398</th>\n","      <td>399</td>\n","      <td>312</td>\n","      <td>103</td>\n","      <td>3</td>\n","      <td>3.5</td>\n","      <td>4.0</td>\n","      <td>8.78</td>\n","      <td>0</td>\n","      <td>0.67</td>\n","    </tr>\n","    <tr>\n","      <th>399</th>\n","      <td>400</td>\n","      <td>333</td>\n","      <td>117</td>\n","      <td>4</td>\n","      <td>5.0</td>\n","      <td>4.0</td>\n","      <td>9.66</td>\n","      <td>1</td>\n","      <td>0.95</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>400 rows × 9 columns</p>\n","</div>"],"text/plain":["     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n","0             1        337          118                  4  4.5   4.5  9.65   \n","1             2        324          107                  4  4.0   4.5  8.87   \n","2             3        316          104                  3  3.0   3.5  8.00   \n","3             4        322          110                  3  3.5   2.5  8.67   \n","4             5        314          103                  2  2.0   3.0  8.21   \n","..          ...        ...          ...                ...  ...   ...   ...   \n","395         396        324          110                  3  3.5   3.5  9.04   \n","396         397        325          107                  3  3.0   3.5  9.11   \n","397         398        330          116                  4  5.0   4.5  9.45   \n","398         399        312          103                  3  3.5   4.0  8.78   \n","399         400        333          117                  4  5.0   4.0  9.66   \n","\n","     Research  Chance of Admit   \n","0           1              0.92  \n","1           1              0.76  \n","2           1              0.72  \n","3           1              0.80  \n","4           0              0.65  \n","..        ...               ...  \n","395         1              0.82  \n","396         1              0.84  \n","397         1              0.91  \n","398         0              0.67  \n","399         1              0.95  \n","\n","[400 rows x 9 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Define the input and output data\n","X = data.iloc[:, 1:8].values # select columns 1-7 with all rows\n","y = data.iloc[:, 8].values # select 8th column"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"],"text/plain":["LinearRegression()"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Train the linear regression model\n","regressor = LinearRegression()\n","regressor.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["array([0.65574435, 0.73430228, 0.90436809, 0.82259969, 0.55788233,\n","       0.91160429, 0.54264953, 0.52628146, 0.66340936, 0.81851662,\n","       0.68593422, 0.93401326, 0.53815533, 0.86728918, 0.69609912,\n","       0.65125774, 0.67311052, 0.51406476, 0.69792256, 1.00910305,\n","       0.55736174, 0.62087043, 0.74014935, 0.53946085, 0.91009173,\n","       0.83559979, 0.67767011, 0.56291224, 0.68639694, 0.78926028,\n","       0.83817553, 0.95031015, 0.66204304, 0.48865961, 0.66414965,\n","       0.64822431, 0.70045985, 0.673208  , 0.60509982, 0.85898307,\n","       0.77063988, 0.58089016, 0.75263348, 0.93347497, 0.83261751,\n","       0.86772458, 0.93092666, 0.63943982, 0.89463172, 0.85382072,\n","       0.872162  , 0.75161614, 0.82011878, 0.9320531 , 0.60990902,\n","       0.56969517, 0.68880011, 0.83945734, 0.56622967, 0.84683954,\n","       0.65260813, 0.66365908, 0.72015857, 0.48817044, 0.6102768 ,\n","       0.68964218, 0.64532972, 0.85752904, 0.89112601, 0.77430894,\n","       0.74441559, 0.79456207, 0.84202392, 0.80971924, 0.55237768,\n","       0.72458004, 0.69319436, 0.61337997, 0.88147516, 0.76925364])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# predict the test results\n","y_pred = regressor.predict(X_test)\n","y_pred"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8212241793299232\n"]}],"source":["# calculate R-squared\n","accuracy = r2_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MSE: 0.004616592264723946\n"]}],"source":["# predict Mean squared error (MSE)\n","mse = mean_squared_error(y_test, y_pred)\n","print(\"MSE:\", mse)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 0.04994339166543273\n"]}],"source":["# predict Mean absolute error (MAE)\n","mae = mean_absolute_error(y_test, y_pred)\n","print(\"MAE:\", mae)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE: 0.06794550952582477\n"]}],"source":["# predict Root mean squared error (RMSE)\n","rmse = mean_squared_error(y_test, y_pred, squared=False)\n","print(\"RMSE:\", rmse)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["precision_at_k=5:  0.942\n"]}],"source":["# function for precision at k\n","def precision_at_k(y_test, y_pred, k):\n","\n","    # sort the prediction values by probability in descending order\n","    sorted_pred_values = np.argsort(y_pred)[::-1] \n","\n","    # select the top k sorted prediction values\n","    top_k_sorted_pred_values = sorted_pred_values[:k]\n","\n","    # precision at k\n","    true_positives = np.sum(y_test[top_k_sorted_pred_values])\n","    precision_at_k = true_positives / k\n","\n","    return precision_at_k\n","\n","# precision at k=5\n","precision_at_5 = precision_at_k(y_test, y_pred, k=5)\n","print(\"precision_at_k=5: \", precision_at_5)"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
